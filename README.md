# Image-Caption-Generation-using-CNN---GRU
Automatically generating human-like captions for images using deep learning (CNN-GRU). This project was published in an IEEE Conference and explores image captioning using a combination of Convolutional Neural Networks (CNN) and Gated Recurrent Units (GRU).
Published in: IEEE Conference
ğŸ“Œ Technologies Used: CNN (ResNet-50) + GRU for image captioning
ğŸ“Š Evaluation Metrics: BLEU, METEOR, CIDEr
ğŸ—‚ï¸ Dataset: Flickr8k, Flickr30k


âœ¨ Features
âœ… End-to-End Deep Learning Pipeline (Image Processing â†’ Feature Extraction â†’ Caption Generation)
âœ… CNN-GRU Model for accurate captioning
âœ… Pretrained ResNet-50 for feature extraction
âœ… Word Embeddings (GloVe - 300D) for text understanding
âœ… Optimized with Adam Optimizer for better training stability
âœ… Comparison with LSTM & RNN-based approaches
âœ… BLEU-4 score of 0.421 (higher than CNN-LSTM)


ğŸ“š Dataset
We used two major datasets:

Flickr8k (8,000 images with 5 captions each)
Flickr30k (30,000 images with 5 captions each)
ğŸ“¸ Image Preprocessing:

Resized to 224Ã—224 pixels
Normalized pixel values
Data Augmentation for better generalization

ğŸ“ Text Preprocessing:

Tokenization & Stemming
GloVe Embeddings for NLP
Sequence Padding for uniform input size
ğŸ— Methodology
1ï¸âƒ£ CNN - Image Feature Extraction
We use ResNet-50 (a powerful CNN) to extract 2048-dimensional feature vectors from images.

2ï¸âƒ£ GRU - Caption Generation
A Gated Recurrent Unit (GRU) processes image features and generates word-by-word captions.

3ï¸âƒ£ Training & Optimization
Loss Function: Cross-Entropy Loss
Optimizer: Adam

Model perfomance:
Model	BLEU-1	BLEU-2	BLEU-3	BLEU-4	METEOR	CIDEr
CNN-GRU	0.743	0.614	0.506	0.421	0.332	0.652
CNN-LSTM	0.714	0.585	0.473	0.391	0.312	0.603
CNN-RNN	0.682	0.558	0.432	0.347	0.274	0.536

ğŸ† Key Insight:
CNN-GRU outperformed CNN-LSTM and CNN-RNN in all major NLP evaluation metrics!
